{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music tagging Transformer\n",
    "This file traines a transformer from the melspectogram features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import save_utils\n",
    "from plot import plot_hist, plot_conf_mat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    GlobalAvgPool1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    ")\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from transformer import Encoder\n",
    "\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.ops import clip_ops"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define crossentropy and accuracy metric for the training routine\n",
    "For the metric we use a binary accuracy, for the loss a binary cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_binary_accuracy(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"Calculating the accuracy for the model where the treshold is 0.5 and the result will be between 0 and 1\n",
    "    \"\"\"\n",
    "    threshold = math_ops.cast(threshold, y_pred.dtype)\n",
    "    y_pred = math_ops.cast(y_pred > threshold, y_pred.dtype)\n",
    "    y_true = math_ops.cast(y_true > threshold, y_true.dtype)\n",
    "\n",
    "    return K.mean(math_ops.equal(y_true, y_pred), axis=-1)\n",
    "\n",
    "\n",
    "def custom_binary_crossentropy(y_true, y_pred):\n",
    "    \"\"\"Calculating the cross entropy from probabilities where the result will be between 0 and 1\n",
    "    \"\"\"\n",
    "    y_pred = ops.convert_to_tensor(y_pred)\n",
    "    y_true = math_ops.cast(y_true, y_pred.dtype)\n",
    "    epsilon_ = K._constant_to_tensor(K.epsilon(), y_pred.dtype.base_dtype)\n",
    "    output = clip_ops.clip_by_value(y_pred, epsilon_, 1.0 - epsilon_)\n",
    "\n",
    "    # Compute cross entropy from probabilities.\n",
    "    bce = 4 * y_true * math_ops.log(output + K.epsilon())\n",
    "    bce += (1 - y_true) * math_ops.log(1 - output + K.epsilon())\n",
    "    return K.sum(-bce, axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model\n",
    "Define the transformer model structure with the Encoder from the transformer util file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_model(model_config, n_classes):\n",
    "    \"\"\"Transformer model where the model will be trained on the training data\n",
    "    \"\"\"\n",
    "    num_layers = model_config['n_layers']\n",
    "    d_model = model_config['d_model']\n",
    "    num_heads = model_config['n_heads']\n",
    "    dff = model_config['dff']\n",
    "    maximum_position_encoding = model_config['max_pos_encoding']\n",
    "    init_lr = model_config['init_learning_rate']\n",
    "    dropout_rate = model_config['dropout_rate']\n",
    "    activations = model_config['activations']\n",
    "\n",
    "    input_layer = Input((None, d_model))\n",
    "    #Getting the encoder code from the transformer\n",
    "    encoder = Encoder(\n",
    "        num_layers=num_layers,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dff=dff,\n",
    "        maximum_position_encoding=maximum_position_encoding,\n",
    "        rate=model_config['encoder_rate']\n",
    "    )\n",
    "\n",
    "    x = encoder(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = GlobalAvgPool1D()(x)\n",
    "    x = Dense(4 * n_classes, activation=activations[0])(x)\n",
    "\n",
    "    out = Dense(n_classes, activation=activations[1])(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=out)\n",
    "    model.compile(optimizer=Adam(init_lr), loss=custom_binary_crossentropy, metrics=[custom_binary_accuracy])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main routine\n",
    "## Load the configuration for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the config\n",
    "with open('music_tag_transformer/transformer_config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract the values\n",
    "transformer_name = config['transformer_name']\n",
    "transformer_pretrained_name = config['pretrained_transformer']\n",
    "batch_size = config['batch_size']\n",
    "epochs = config['epochs']\n",
    "data_dir = Path(config['data_dir'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data\n",
    "Load the numpy arrays and the label-class mapping. Split the data accordingly into train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 files:\n",
      "    melspec_features_001.npy\n",
      "    melspec_features_002.npy\n",
      "    melspec_features_003.npy\n",
      "    melspec_features_007.npy\n",
      "    melspec_features_012.npy\n",
      "    melspec_features_006.npy\n",
      "    melspec_features_010.npy\n",
      "    melspec_features_004.npy\n",
      "    melspec_features_005.npy\n",
      "    melspec_features_011.npy\n",
      "    melspec_features_008.npy\n",
      "    melspec_features_009.npy\n"
     ]
    }
   ],
   "source": [
    "melspec_data = save_utils.load_sliced_numpy_array('melspec_features', data_dir=data_dir)\n",
    "labels = np.load(data_dir/'labels.npy')\n",
    "\n",
    "with open(data_dir/'class_label_index_mapping.json', 'r') as f:\n",
    "    labels_to_id = json.load(f)\n",
    "\n",
    "mel_train, mel_test_val, lab_train, lab_test_val = train_test_split(melspec_data, labels, train_size=config['train_set_size'], random_state=config['random_state'])\n",
    "mel_val, mel_test, lab_val, lab_test             = train_test_split(mel_test_val, lab_test_val, test_size=(config['val_set_size']/(1-config['train_set_size'])), shuffle=False)\n",
    "\n",
    "# Check the shapes of the splitted sets\n",
    "assert mel_train.shape[0] == lab_train.shape[0] and mel_test.shape[0] == lab_test.shape[0] and mel_val.shape[0] == lab_val.shape[0]\n",
    "assert mel_train.shape[1] == mel_test.shape[1] == mel_val.shape[1] and lab_train.shape[1] == lab_test.shape[1] == lab_val.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the model callbacks\n",
    "For the initializing parameters, refer to the config file.  \n",
    "For callbacks, we use a frequently backup of the model as checkpoints, and early stopping mechanism to prevent overfitting on the training data and a learningrate reducer, that smallers the update steps when the validation metric does not improve any more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = config['training']\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    transformer_name,\n",
    "    monitor=train_config['monitor'],\n",
    "    verbose=1,\n",
    "    save_best_only=train_config['save_best_weights'],\n",
    "    mode=train_config['monitor_mode'],\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    patience = 10,\n",
    "    verbose = 1,\n",
    "    mode = 'min',\n",
    "    restore_best_weights = True,\n",
    "    start_from_epoch = 5\n",
    ")\n",
    "\n",
    "# Reduce learning rate when val_loss stopps improving\n",
    "lr_reduce_config = train_config['lr_reducing']\n",
    "lr_reducing_on_platteau = ReduceLROnPlateau(\n",
    "    monitor=lr_reduce_config['monitor'], patience=lr_reduce_config['patience'], min_lr=lr_reduce_config['min_lr'], mode=lr_reduce_config['mode']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 17:50:54.717651: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 128)]       0         \n",
      "                                                                 \n",
      " encoder (Encoder)           (None, None, 128)         529920    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 5)                 105       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 532,605\n",
      "Trainable params: 532,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 5.55423, saving model to transformer.h5\n",
      "77/77 - 179s - loss: 5.9136 - custom_binary_accuracy: 0.5135 - val_loss: 5.5542 - val_custom_binary_accuracy: 0.8000 - lr: 0.0010 - 179s/epoch - 2s/step\n",
      "Epoch 2/40\n",
      "\n",
      "Epoch 2: val_loss did not improve from 5.55423\n",
      "77/77 - 196s - loss: 5.5849 - custom_binary_accuracy: 0.5292 - val_loss: 5.6584 - val_custom_binary_accuracy: 0.4698 - lr: 0.0010 - 196s/epoch - 3s/step\n",
      "Epoch 3/40\n",
      "\n",
      "Epoch 3: val_loss did not improve from 5.55423\n",
      "77/77 - 196s - loss: 5.5519 - custom_binary_accuracy: 0.5366 - val_loss: 5.5686 - val_custom_binary_accuracy: 0.6909 - lr: 0.0010 - 196s/epoch - 3s/step\n",
      "Epoch 4/40\n",
      "\n",
      "Epoch 4: val_loss improved from 5.55423 to 5.53222, saving model to transformer.h5\n",
      "77/77 - 191s - loss: 5.5406 - custom_binary_accuracy: 0.5120 - val_loss: 5.5322 - val_custom_binary_accuracy: 0.4698 - lr: 0.0010 - 191s/epoch - 2s/step\n",
      "Epoch 5/40\n",
      "\n",
      "Epoch 5: val_loss improved from 5.53222 to 5.52880, saving model to transformer.h5\n",
      "77/77 - 196s - loss: 5.5442 - custom_binary_accuracy: 0.5070 - val_loss: 5.5288 - val_custom_binary_accuracy: 0.4698 - lr: 0.0010 - 196s/epoch - 3s/step\n",
      "Epoch 6/40\n",
      "\n",
      "Epoch 6: val_loss did not improve from 5.52880\n",
      "77/77 - 122s - loss: 5.5563 - custom_binary_accuracy: 0.5380 - val_loss: 5.5973 - val_custom_binary_accuracy: 0.8000 - lr: 0.0010 - 122s/epoch - 2s/step\n",
      "Epoch 7/40\n",
      "\n",
      "Epoch 7: val_loss improved from 5.52880 to 5.49233, saving model to transformer.h5\n",
      "77/77 - 118s - loss: 5.5497 - custom_binary_accuracy: 0.5337 - val_loss: 5.4923 - val_custom_binary_accuracy: 0.4784 - lr: 0.0010 - 118s/epoch - 2s/step\n",
      "Epoch 8/40\n",
      "\n",
      "Epoch 8: val_loss did not improve from 5.49233\n",
      "77/77 - 116s - loss: 5.5261 - custom_binary_accuracy: 0.4991 - val_loss: 5.7753 - val_custom_binary_accuracy: 0.5474 - lr: 0.0010 - 116s/epoch - 2s/step\n",
      "Epoch 9/40\n",
      "\n",
      "Epoch 9: val_loss did not improve from 5.49233\n",
      "77/77 - 117s - loss: 5.5414 - custom_binary_accuracy: 0.5201 - val_loss: 5.5271 - val_custom_binary_accuracy: 0.5779 - lr: 0.0010 - 117s/epoch - 2s/step\n",
      "Epoch 10/40\n",
      "\n",
      "Epoch 10: val_loss did not improve from 5.49233\n",
      "77/77 - 120s - loss: 5.5239 - custom_binary_accuracy: 0.5407 - val_loss: 5.5560 - val_custom_binary_accuracy: 0.4568 - lr: 0.0010 - 120s/epoch - 2s/step\n",
      "Epoch 11/40\n",
      "\n",
      "Epoch 11: val_loss did not improve from 5.49233\n",
      "77/77 - 119s - loss: 5.4574 - custom_binary_accuracy: 0.5239 - val_loss: 5.6272 - val_custom_binary_accuracy: 0.6231 - lr: 0.0010 - 119s/epoch - 2s/step\n",
      "Epoch 12/40\n",
      "\n",
      "Epoch 12: val_loss improved from 5.49233 to 5.44374, saving model to transformer.h5\n",
      "77/77 - 117s - loss: 5.4129 - custom_binary_accuracy: 0.5554 - val_loss: 5.4437 - val_custom_binary_accuracy: 0.6054 - lr: 0.0010 - 117s/epoch - 2s/step\n",
      "Epoch 13/40\n",
      "\n",
      "Epoch 13: val_loss improved from 5.44374 to 5.25018, saving model to transformer.h5\n",
      "77/77 - 111s - loss: 5.3082 - custom_binary_accuracy: 0.5519 - val_loss: 5.2502 - val_custom_binary_accuracy: 0.5189 - lr: 0.0010 - 111s/epoch - 1s/step\n",
      "Epoch 14/40\n",
      "\n",
      "Epoch 14: val_loss did not improve from 5.25018\n",
      "77/77 - 112s - loss: 5.3343 - custom_binary_accuracy: 0.5528 - val_loss: 5.2835 - val_custom_binary_accuracy: 0.5027 - lr: 0.0010 - 112s/epoch - 1s/step\n",
      "Epoch 15/40\n",
      "\n",
      "Epoch 15: val_loss did not improve from 5.25018\n",
      "77/77 - 112s - loss: 5.2119 - custom_binary_accuracy: 0.5660 - val_loss: 5.4894 - val_custom_binary_accuracy: 0.5307 - lr: 0.0010 - 112s/epoch - 1s/step\n",
      "Epoch 16/40\n",
      "\n",
      "Epoch 16: val_loss improved from 5.25018 to 5.12859, saving model to transformer.h5\n",
      "77/77 - 111s - loss: 5.2015 - custom_binary_accuracy: 0.5439 - val_loss: 5.1286 - val_custom_binary_accuracy: 0.5597 - lr: 0.0010 - 111s/epoch - 1s/step\n",
      "Epoch 17/40\n",
      "\n",
      "Epoch 17: val_loss did not improve from 5.12859\n",
      "77/77 - 120s - loss: 5.2243 - custom_binary_accuracy: 0.5631 - val_loss: 5.3056 - val_custom_binary_accuracy: 0.5354 - lr: 0.0010 - 120s/epoch - 2s/step\n",
      "Epoch 18/40\n",
      "\n",
      "Epoch 18: val_loss did not improve from 5.12859\n",
      "77/77 - 121s - loss: 5.1620 - custom_binary_accuracy: 0.5587 - val_loss: 5.1571 - val_custom_binary_accuracy: 0.5533 - lr: 0.0010 - 121s/epoch - 2s/step\n",
      "Epoch 19/40\n",
      "\n",
      "Epoch 19: val_loss did not improve from 5.12859\n",
      "77/77 - 121s - loss: 5.1294 - custom_binary_accuracy: 0.5711 - val_loss: 5.2140 - val_custom_binary_accuracy: 0.5816 - lr: 0.0010 - 121s/epoch - 2s/step\n",
      "Epoch 20/40\n",
      "\n",
      "Epoch 20: val_loss improved from 5.12859 to 4.95982, saving model to transformer.h5\n",
      "77/77 - 119s - loss: 5.0876 - custom_binary_accuracy: 0.5707 - val_loss: 4.9598 - val_custom_binary_accuracy: 0.5705 - lr: 0.0010 - 119s/epoch - 2s/step\n",
      "Epoch 21/40\n",
      "\n",
      "Epoch 21: val_loss did not improve from 4.95982\n",
      "77/77 - 123s - loss: 5.0802 - custom_binary_accuracy: 0.5697 - val_loss: 5.0630 - val_custom_binary_accuracy: 0.5695 - lr: 0.0010 - 123s/epoch - 2s/step\n",
      "Epoch 22/40\n",
      "\n",
      "Epoch 22: val_loss did not improve from 4.95982\n",
      "77/77 - 120s - loss: 5.3463 - custom_binary_accuracy: 0.5230 - val_loss: 5.5523 - val_custom_binary_accuracy: 0.4698 - lr: 0.0010 - 120s/epoch - 2s/step\n",
      "Epoch 23/40\n",
      "\n",
      "Epoch 23: val_loss did not improve from 4.95982\n",
      "77/77 - 112s - loss: 5.4983 - custom_binary_accuracy: 0.4999 - val_loss: 5.4740 - val_custom_binary_accuracy: 0.4993 - lr: 0.0010 - 112s/epoch - 1s/step\n",
      "Epoch 24/40\n",
      "\n",
      "Epoch 24: val_loss did not improve from 4.95982\n",
      "77/77 - 117s - loss: 5.2536 - custom_binary_accuracy: 0.5561 - val_loss: 5.2044 - val_custom_binary_accuracy: 0.5639 - lr: 0.0010 - 117s/epoch - 2s/step\n",
      "Epoch 25/40\n",
      "\n",
      "Epoch 25: val_loss did not improve from 4.95982\n",
      "77/77 - 118s - loss: 5.2020 - custom_binary_accuracy: 0.5495 - val_loss: 5.2389 - val_custom_binary_accuracy: 0.4826 - lr: 0.0010 - 118s/epoch - 2s/step\n",
      "Epoch 26/40\n",
      "\n",
      "Epoch 26: val_loss did not improve from 4.95982\n",
      "77/77 - 125s - loss: 5.1995 - custom_binary_accuracy: 0.5502 - val_loss: 5.2944 - val_custom_binary_accuracy: 0.5152 - lr: 0.0010 - 125s/epoch - 2s/step\n",
      "Epoch 27/40\n",
      "\n",
      "Epoch 27: val_loss did not improve from 4.95982\n",
      "77/77 - 126s - loss: 5.1062 - custom_binary_accuracy: 0.5585 - val_loss: 5.3986 - val_custom_binary_accuracy: 0.5405 - lr: 0.0010 - 126s/epoch - 2s/step\n",
      "Epoch 28/40\n"
     ]
    }
   ],
   "source": [
    "# read in the config\n",
    "with open('preprocess_config.yaml', 'r') as f:\n",
    "    pp_config = yaml.safe_load(f)\n",
    "\n",
    "n_mels = pp_config['melspectogram']['n_mels']\n",
    "mel_train = mel_train.reshape(mel_train.shape[0], -1, n_mels)\n",
    "mel_val   = mel_val.reshape(mel_val.shape[0], -1, n_mels)\n",
    "\n",
    "model = transformer_model(config['model_structure'], n_classes=len(labels_to_id))\n",
    "\n",
    "history = model.fit(\n",
    "        x=mel_train,\n",
    "        y=lab_train,\n",
    "        validation_data=(mel_val, lab_val),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint, lr_reducing_on_platteau, early_stopping],\n",
    "        use_multiprocessing=True,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "model.save('models/complete'+transformer_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dump the history to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'models/{transformer_name}_history{epochs}', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'models/{transformer_name}_history{epochs}', \"rb\") as f:\n",
    "    history_dict = pickle.load(f)\n",
    "\n",
    "print('available keys', history_dict.keys())\n",
    "\n",
    "#Plots for the accuracies and losses of the train and validation data per epoch\n",
    "plot_hist(history_dict, ('accuracy', 'val_accuracy'), legends=('train', 'validation'), title='Accuracy', y_label='accuracy ->', x_label='epochs ->', save_to=f'Plots/short_chunk_cnn_{epochs}_acuracy')\n",
    "plot_hist(history_dict, ('loss', 'val_loss'), legends=('train', 'validation'), title='Loss', y_label='loss ->', x_label='epochs ->', save_to=f'Plots/short_chunk_cnn_{epochs}_loss')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict model output on all the available sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = lambda model, data: np.argmax(model.predict(data), axis=-1)\n",
    "\n",
    "#Loading in the model\n",
    "model = load_model(f\"models/{transformer_name}{epochs}.h5\")\n",
    "\n",
    "# Training prediction\n",
    "y_pred_train = predict(model, mel_train)\n",
    "y_true_train = np.argmax(lab_train, axis= -1)\n",
    "print(f\"ACCURACY FOR TRAIN SET {accuracy_score(y_true_train, y_pred_train)*100:.4f} %\")\n",
    "print(f\"MACRO F1 SCORE FOR TRAIN SET {f1_score(y_true_train, y_pred_train, average='macro')*100:.4f} %\")\n",
    "print(f\"MICRO F1 SCORE FOR TRAIN SET {f1_score(y_true_train, y_pred_train, average='micro')*100:.4f} %\")\n",
    "\n",
    "\n",
    "# Validation prediction\n",
    "y_pred_val = predict(model, mel_val)\n",
    "y_true_val = np.argmax(lab_val, axis= -1)\n",
    "print(f\"ACCURACY FOR VAL SET {accuracy_score(y_true_val, y_pred_val)*100:.4f} %\")\n",
    "print(f\"MACRO F1 SCORE FOR VAL SET {f1_score(y_true_val, y_pred_val, average='macro')*100:.4f} %\")\n",
    "print(f\"MICRO F1 SCORE FOR VAL SET {f1_score(y_true_val, y_pred_val, average='micro')*100:.4f} %\")\n",
    "\n",
    "# Test prediction\n",
    "y_pred_test = predict(model, mel_test)\n",
    "y_true_test = np.argmax(lab_test, axis= -1)\n",
    "print(f\"ACCURACY FOR TEST SET {accuracy_score(y_true_test, y_pred_test)*100:.4f} %\")\n",
    "print(f\"MACRO F1 SCORE FOR TEST SET {f1_score(y_true_test, y_pred_test, average='macro')*100:.4f} %\")\n",
    "print(f\"MICRO F1 SCORE FOR TEST SET {f1_score(y_true_test, y_pred_test, average='micro')*100:.4f} %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/class_label_index_mapping.json', 'r') as f:\n",
    "    class_names = json.load(f).keys()\n",
    "\n",
    "#Confusion matrix of the predicted labels versus the true labels\n",
    "conf_mat = confusion_matrix(y_true_test, y_pred_test, normalize= 'true')\n",
    "conf_mat = np.round(conf_mat, 2)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns=class_names, index=class_names)\n",
    "\n",
    "plot_conf_mat(conf_mat_df, save_to=f\"Plots/{transformer_name}{epochs}_test_conf_mat.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-industry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca8db3ad7877ac29be891f762e2f8f2bd0b14f50820e5ea7ad73e7636a7ffe5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
